# 食物卡路里論文整理(中文)

## 輸入/輸出

使用者輸入一張照片，輸出此食物(可能多種)的質量的總和

## 架構
1. 食物辨識
    使用已訓練好的YOLOv4進行遷移學習(transfer learning)
    
    > The state-of-the-art YOLOv4-tiny (24) was employed for the object detection task. Transfer learning was used to retrain a Microsoft Common Objects in Context (MS COCO) pre-trained model for the newly developed dataset. Darknet was used initially for training, and the trained model ran on OpenCV’s dnn module after being trained well.

2. 食物切割
    使用GrabCut進行自動化切割
    > The classic GrabCut (25) was used for image segmentation.

3. 質量預測
    使用類神經網路估計食物質量
    此預測的方式的輸入有兩種
    - 含參考物(湯匙)(11x1):
        食物的xmin, ymin, xmax, ymax, 食物種類, 拍攝角度, 參考物的xmin, ymin, xmax, ymax, 參考物位置
    - 不含參考物(6x1):
        食物的xmin, ymin, xmax, ymax, 食物種類, 拍攝角度
    
    此模型有三層神經網路(100,50,25)個節點,最後一個節點則是質量輸出
    除此之外，此模型使用了ReLU作為每層的activation function
    
    Loss function 為 MSE(mean squared error)，並使用Adam optimization
    
    
    > The regression model consists of an input layer, three dense hidden layers with 100, 50, and 25 nodes, and 1 node of the dense output layer. Rectified linear units were used for the activation function between each layer, and mean squared error was used for loss function with Adam optimization. An 11 × 1 input layer, matching the food item area and the location of it, referring to values of xmin, ymin, xmax, ymax, the reference object area, reference object location of the same image, and shooting angle, was used for training spoon-corrected models. A 6 × 1 input layer was used for training no-spoon-corrected models using the same data, but reference object information was omitted.

## 流程
1. 取得食物照片
2. 使用YOLO辨識食物的種類以及範圍
3. 使用GrabCut自動切除與食物不相關的部分
4. 輸入與食物相關的資訊，估計食物質量
5. 查詢食物的表格，計算出營養資訊與碳水化合物，並把全部結果加總


> After the image acquisition process, an object detector identified the areas of food components in each image. The food code and region-of-interest (ROI) were sent to the segmentation unit wherein non-food regions were removed automatically. Incorporating the angle at which each photo was taken, the segmented food component images were transferred to the weight estimation unit. Finally, the estimated weight of each food component was sent to the food composition computational unit to determine nutritive values and the amount of carbohydrates. The summation of all nutrients for each food component was used to report the nutritive values of each food image.

## 資料集
此資料集是由他們自行建構，總共有175食物原料

> According to a previous report (27), 80% of carbohydrates consumed by the Thai population frequently come from only 93 food items as determined by the INMUCal-Nutrients software (28). Hence, these items were included in the newly developed dataset. For expanding coverage in real life, some traditional Thai desserts, favorite tropical fruits, and vegetables, as well as meats, were also included in the dataset. The final image dataset contained 175 food item classes.

基本上，沒有食物覆蓋在其他食物上，除了一些特例。對於這種情況，會拍攝兩種(有食材覆蓋與無覆蓋)情況
> Generally, no part of the food was covered by another food. However, for some menus consisting of rice topped with cooked meat, curry, or an opaque sauce, they were arranged to have photos taken both with and without toppings.

每種食物都使用電子秤計算質量，並根據四捨五入法。除此之外，不同種類的湯匙被隨機擺放在食物旁，用來當做參考物件

> All the food portions were measured using a digital kitchen scale and rounded to the nearest integer, for instance, 63.4 and 55.5 g were rounded to 63 and 56 g, respectively. Various shapes of tablespoons were randomly placed on plates along with the foods to be used as reference objects.

食物根據三種不同的角度拍攝(30,60,90)

> Three Android smartphones were attached to three camera tripods to take photos from three different angles (30◦ , 60◦ , and 90◦ from the tabletop). While the rotating plate was operating, burst shots were taken to capture pictures simultaneously, resulting in a series of multi-angle food images

去除重覆與低清的照片後，將每個照片縮放至800x800

>After the removal of low-quality or duplicated images, the remaining images were resized into 800 × 800 pixels using Lanczos algorithms to allow the annotators to function conveniently in any device. All visible food components were annotated separately in the same fashion as that for Thai dietitians, and only the head (bowl) part of a spoon was annotated as a reference object.

訓練與測試資料分成80%/20%，並且三種不同角度的照片被平均分配

> For each food class type, the dataset was split into 80% for training and 20% for testing from three different angles equally
## 精準度

使用測試集的結果為80.9%

> The system demonstrated Top-1 accuracy at 80.9% for food recognition in the test dataset.

以下是與其他論文比較的結果
<img src="https://hackmd.io/_uploads/SJdXElvx6.png" height="400px">
<img src="https://hackmd.io/_uploads/ryvfBlwxp.png" width="400px">
<img src="https://hackmd.io/_uploads/Hkazrlwla.png" width="400px">


---

# Research Paper Arrangment(英文)
## Input / Output
Users take a single picture as the input, the output will be the quality of the given food (Can be multiple types)

## Architecture

## Dataset

## Precision


---

![](https://hackmd.io/_uploads/S1SwGQde6.png)

## 推薦系統
https://ieeexplore.ieee.org/document/9775081
### 輸入/輸出
輸入為用戶對部分食物的評分
輸出為推薦食物的串列(根據最適合的食物排序)
### 架構
1. FOOD DEEP EMBEDDING
    使用Bert將食物中的食材，轉變成n維度的embedding
2. FOOD SIMILARITY CALCULATION
    計算兩個食物的差距
3. FOOD CLUSTERING
    使用Deep Embedded Clustering的技巧，把關聯的食物聚集
### 資料集
使用爬蟲爬取 Allrecipes.com
>  In total, 68,768 users, 45,630 foods with 33,147 ingredients, and 1,093,845 ratings were collected.
### 準確度
<img src="https://hackmd.io/_uploads/rJD17-uep.png" width="400px">
<img src="https://hackmd.io/_uploads/Syqxm-dg6.png" width="400px">

### 目前的問題
1. 此篇論文只有參考食物的原料
2. 沒有與計算卡路里模型連結的部分