{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SppYpQ8DJWjf"
      },
      "source": [
        "**Download dataset from Roboflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL4Iuh_Zpvfu",
        "outputId": "68681b30-47a1-4592-a6fc-25a8eb30c673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.12)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.45.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: scipy<=2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Food-7 to yolov5pytorch:: 100%|██████████| 1914/1914 [00:00<00:00, 2994.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Food-7 in yolov5pytorch:: 100%|██████████| 90/90 [00:00<00:00, 4376.61it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"lttzJNap0h9lODifvr4O\")\n",
        "project = rf.workspace(\"school-yrws4\").project(\"food-pion4\")\n",
        "dataset = project.version(7).download(\"yolov5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DglgncJiNq"
      },
      "source": [
        "**Write on CSV file with the annotation files**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSK8ef2gKG7v",
        "outputId": "ded0c54d-206b-47cf-c75f-707679988d2a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uZXL5oLVqEQ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def process_label_file(file_path):\n",
        "    objects = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 5:  # Ensure there are 5 elements in the line\n",
        "                object_id, x_center, y_center, width, height = map(float, parts)\n",
        "                objects.append([object_id, x_center, y_center, width, height, '', '', ''])  # Leaving area and mass empty\n",
        "    return objects\n",
        "\n",
        "def get_processed_images(csv_file):\n",
        "    processed_images = set()\n",
        "    if os.path.exists(csv_file):\n",
        "        with open(csv_file, 'r') as csvfile:\n",
        "            reader = csv.reader(csvfile)\n",
        "            next(reader, None)  # Skip header\n",
        "            for row in reader:\n",
        "                if row:\n",
        "                    processed_images.add(row[0])\n",
        "    return processed_images\n",
        "\n",
        "def adjust_image_name(image_name):\n",
        "    for ext in ['jpg', 'jpeg']:\n",
        "        index = image_name.find('_' + ext)\n",
        "        if index != -1:\n",
        "            return image_name[:index]\n",
        "    return image_name  # Return original name if no match\n",
        "\n",
        "def process_dataset(dataset_path, output_csv):\n",
        "    processed_images = get_processed_images(output_csv)\n",
        "    data_to_write = []\n",
        "    for folder in ['train', 'test', 'valid']:\n",
        "        label_path = os.path.join(dataset_path, folder, 'labels')\n",
        "        for label_file in os.listdir(label_path):\n",
        "            if label_file.endswith('.txt'):\n",
        "                image_name = label_file.replace('.txt', '')\n",
        "                adjusted_image_name = adjust_image_name(image_name)\n",
        "                if adjusted_image_name not in processed_images:\n",
        "                    objects = process_label_file(os.path.join(label_path, label_file))\n",
        "                    for obj in objects:\n",
        "                        data_to_write.append([adjusted_image_name] + obj)\n",
        "\n",
        "    return data_to_write\n",
        "\n",
        "def write_to_csv(data, output_csv):\n",
        "    if_exist = os.path.exists(output_csv)\n",
        "    mode = 'a' if if_exist else 'w'\n",
        "    with open(output_csv, mode, newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        if if_exist == False:\n",
        "          csv_writer.writerow(['image_name', 'object_id', 'x_center', 'y_center', 'width', 'height', 'image_area', 'area', 'mass'])\n",
        "        csv_writer.writerows(data)\n",
        "\n",
        "def sort_csv_data(csv_file):\n",
        "    with open(csv_file, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        header = next(reader)\n",
        "        sorted_data = sorted(reader, key=lambda x: x[0])  # Sort by image name\n",
        "\n",
        "    with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(header)\n",
        "        writer.writerows(sorted_data)\n",
        "\n",
        "\n",
        "dataset_path = os.path.join(HOME, \"Food-7\")\n",
        "output_csv = os.path.join(HOME, \"output.csv\")\n",
        "data_to_write = process_dataset(dataset_path, output_csv)\n",
        "\n",
        "write_to_csv(data_to_write, output_csv)\n",
        "sort_csv_data(output_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhNby4YDJrxJ"
      },
      "source": [
        "**Load SAM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVWjABr8un18",
        "outputId": "a6b147bf-4a24-4b95-ec29-87ba29fea370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bcc80WnZuzDr"
      },
      "outputs": [],
      "source": [
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "sZMnoiHkvAK8"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEKR4M18vGGh",
        "outputId": "51313cf8-120f-4d90-a150-a3d285c97ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/sam_vit_h_4b8939.pth ; exist: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aLIUAhpKvOLE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "hDhPbT89vUit"
      },
      "outputs": [],
      "source": [
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_RbJ6D_Zv6Bm"
      },
      "outputs": [],
      "source": [
        "mask_predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bt6isPfJz3B"
      },
      "source": [
        "**Calculate areas and rewrite on CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "zEHmImcFwncl"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "import csv\n",
        "import os\n",
        "import supervision as v\n",
        "\n",
        "#     # Replace the original file with the updated temp file\n",
        "#     os.remove(csv_file)\n",
        "#     os.rename(temp_file, csv_file)\n",
        "\n",
        "def process_images_and_create_masks(dataset_path, csv_file):\n",
        "    with open(csv_file, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        header = next(reader)  # Skip header\n",
        "        csv_data = list(reader)\n",
        "\n",
        "    rows_temp = []\n",
        "    for folder in ['train', 'test', 'valid']:\n",
        "        image_folder_path = os.path.join(dataset_path, folder, 'images')\n",
        "        for image_file in os.listdir(image_folder_path):\n",
        "            image_name = os.path.splitext(image_file)[0]\n",
        "            adjusted_image_name = adjust_image_name(image_name)\n",
        "\n",
        "            IMAGE_PATH = os.path.join(image_folder_path, image_file)\n",
        "            image_bgr = cv2.imread(IMAGE_PATH)\n",
        "            image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            mask_predictor.set_image(image_rgb)\n",
        "            info = []\n",
        "            for row in csv_data:\n",
        "                if row[0] == adjusted_image_name:\n",
        "                    x_center, y_center, width, height = map(float, row[2:6])\n",
        "                    id = row[1]\n",
        "                    x_min = (x_center * 640) - (width *640) / 2\n",
        "                    y_min = (y_center * 640) - (height *640) / 2\n",
        "                    x_max = (x_center * 640) + (width *640) / 2\n",
        "                    y_max = (y_center * 640) + (height *640) / 2\n",
        "\n",
        "                    bbox = np.array([x_min, y_min, x_max, y_max])\n",
        "\n",
        "                    masks, scores, logits = mask_predictor.predict(\n",
        "                        box=bbox,\n",
        "                        multimask_output= True\n",
        "                    )\n",
        "                    image_area = np.count_nonzero(masks[2])\n",
        "\n",
        "                    # visualize the mask with sv\n",
        "                    # sv.plot_images_grid(\n",
        "                    #     images=masks,\n",
        "                    #     grid_size=(1, 4),\n",
        "                    #     size=(16, 4)\n",
        "                    # )\n",
        "\n",
        "                    # box_annotator = sv.BoxAnnotator(color=sv.Color.red())\n",
        "                    # mask_annotator = sv.MaskAnnotator(color=sv.Color.red(), color_lookup=sv.ColorLookup.INDEX)\n",
        "\n",
        "                    # detections = sv.Detections(\n",
        "                    #     xyxy=sv.mask_to_xyxy(masks=masks),\n",
        "                    #     mask=masks\n",
        "                    # )\n",
        "                    # detections = detections[detections.area == np.max(detections.area)]\n",
        "\n",
        "                    # source_image = box_annotator.annotate(scene=image_bgr.copy(), detections=detections, skip_label=True)\n",
        "                    # segmented_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "                    # sv.plot_images_grid(\n",
        "                    #     images=[source_image, segmented_image],\n",
        "                    #     grid_size=(1, 2),\n",
        "                    #     titles=['source image', 'segmented image']\n",
        "                    # )\n",
        "\n",
        "                    # print(f\"{adjusted_image_name} {id} {image_area}\")\n",
        "                    info.append(row[:6] + [image_area])\n",
        "\n",
        "\n",
        "            coin_image = 0\n",
        "            coin_area = (13**2) * np.pi  # coin area in mm^2\n",
        "            for obj in info:\n",
        "                if float(obj[1])==2.0:\n",
        "                    coin_image = obj[6]\n",
        "\n",
        "            for obj in info:\n",
        "                if coin_image!=0:\n",
        "                    S = obj[6] / coin_image * coin_area\n",
        "                    rows_temp.append(obj + [S, ''])\n",
        "                else:\n",
        "                    rows_temp.append(obj + ['', ''])\n",
        "\n",
        "            del image_bgr\n",
        "            del image_rgb\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    with open(csv_file, 'w') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['image_name', 'object_id', 'x_center', 'y_center', 'width', 'height', 'image_area', 'area', 'mass'])\n",
        "        writer.writerows(rows_temp)\n",
        "    sort_csv_data(csv_file)\n",
        "\n",
        "dataset_path = os.path.join(HOME, \"Food-7\")\n",
        "csv_file = os.path.join(HOME, \"output.csv\")\n",
        "\n",
        "process_images_and_create_masks(dataset_path, csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gxQCwNrllasn"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}